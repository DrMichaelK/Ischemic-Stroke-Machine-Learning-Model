# Ischemic-Stroke-Machine-Learning-Model
This model detects Ischemic Stoke on non contrasted ct scan
The file Stroke Model.ipynb contains the full code for training and evaluating a CNN model to detect ischemic stroke on non-contrast CT scans. It includes data preprocessing, model architecture using TensorFlow/Keras, training on a balanced dataset (500 stroke and 500 normal images), and evaluation using accuracy, precision, recall, F1-score, ROC curve, and confusion matrix. The notebook also visualizes model performance and confirms the modelâ€™s effectiveness in stroke detection.
The file ct data.ipynb handles data loading and preprocessing for the stroke detection model. It includes code to read DICOM and image files, convert them to grayscale, resize them for model input, normalize pixel values, and organize the data into labeled arrays for training and testing. This notebook prepares the balanced dataset used in model training.
The file brain data.ipynb focuses on organizing and labeling brain CT scan images into two categories: stroke and non-stroke. It includes logic for extracting image paths, assigning labels, and displaying sample images for visual inspection. This step ensures clean, structured input data before training the stroke detection model.
The file app.py contains code for a FastAPI-based application that processes brain imaging data for diagnosis. It integrates a deep learning model for classifying conditions such as acute, chronic, lacunar, or normal, and also generates a diagnostic report using a text model. The app handles image input, preprocessing, prediction, and returns results via API endpoints.
The file model.py contains the definition of the deep learning architecture used in this project. It includes a custom ImageToTextProjector module that maps visual embeddings to a textual space, and a CombinedModel class that integrates a video feature extractor, a report generator (e.g., transformer-based model), and a classifier. The combined model handles both classification and report generation tasks, supporting both training and inference. The code utilizes PyTorch and HuggingFace Transformers, making it suitable for multimodal medical applications such as image-based diagnosis with textual reporting.
